{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2QCxjpgrFVWG"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "import portalocker"
      ]
    },
    {
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from collections import Counter\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Define the iterator for building the vocabulary\n",
        "def yield_tokens(data_iter, special_tokens):\n",
        "    # Ensure special tokens are included in the first iteration\n",
        "    for token in special_tokens:\n",
        "        yield [token]\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Special tokens\n",
        "special_tokens = [\"<unk>\", \"<pad>\", \"<start>\", \"<end>\"]\n",
        "\n",
        "# Load the dataset iterator\n",
        "train_iter = IMDB(split='train')\n",
        "\n",
        "# Build the vocabulary with special tokens\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter, special_tokens), specials=special_tokens)\n",
        "\n",
        "# Set default index for unknown tokens\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ty2xCHMlIFcN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xcRLvvIUFVWJ"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(data, n=3):\n",
        "    model = defaultdict(Counter)\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)-n+1):\n",
        "            context = tuple(sentence[i:i+n-1])\n",
        "            target = sentence[i+n-1]\n",
        "            model[context][target] += 1\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bnzmXrNFVWJ",
        "outputId": "134dc931-db57-458f-e2a1-3b25d03f6ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lock acquired. Press Enter to release lock...\n",
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import portalocker\n",
        "with open(\"test.lock\", \"w\") as lock_file:\n",
        "    portalocker.lock(lock_file, portalocker.LOCK_EX)\n",
        "    input(\"Lock acquired. Press Enter to release lock...\")\n",
        "\n",
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CR5ywhkzFVWJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Ensure output layer matches vocab size\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        output = self.fc(output[:, -1, :])  # Assuming you want the last output for classification\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_uPVsnXZFVWJ"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def load_data(data_type='train'):\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "    counter = Counter()\n",
        "    for label, line in IMDB(split=data_type):\n",
        "        counter.update(tokenizer(line))\n",
        "    # Convert the counter to a list of tokens\n",
        "    tokenized_text = [tok for tok, cnt in counter.items() for _ in range(cnt)]\n",
        "    return tokenized_text\n",
        "\n",
        "# Now, using this function, you can load and tokenize your dataset:\n",
        "tokenized_text = load_data('train')  # This should now correctly load and tokenize the text data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uerowftJFVWK"
      },
      "outputs": [],
      "source": [
        "def build_ngram_model(tokenized_text, n=3):\n",
        "    model = {}\n",
        "    for i in range(len(tokenized_text)-n):\n",
        "        gram = tuple(tokenized_text[i:i+n-1])\n",
        "        next_word = tokenized_text[i+n-1]\n",
        "        if gram not in model:\n",
        "            model[gram] = {}\n",
        "        if next_word not in model[gram]:\n",
        "            model[gram][next_word] = 0\n",
        "        model[gram][next_word] += 1\n",
        "    # Convert counts to probabilities\n",
        "    for gram in model.keys():\n",
        "        total = float(sum(model[gram].values()))\n",
        "        for word in model[gram]:\n",
        "            model[gram][word] /= total\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wSaMUwfzFVWK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model, start_text, num_words=20, n=3):\n",
        "    result = start_text.split()\n",
        "    for _ in range(num_words):\n",
        "        state = tuple(result[-(n-1):]) # Last (n-1) words\n",
        "        next_words = model.get(state, None)\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word = random.choices(list(next_words.keys()), weights=next_words.values())[0]\n",
        "        result.append(next_word)\n",
        "    return ' '.join(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_nPjMgpFVWK",
        "outputId": "01d7bdca-9919-42c6-9aac-f112cae798ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n",
            "My favorite movie\n"
          ]
        }
      ],
      "source": [
        "# Example usage (adapt as necessary)\n",
        "tokenized_text = load_data('train')  # Load and tokenize your text data\n",
        "ngram_model = build_ngram_model(tokenized_text, n=3)\n",
        "\n",
        "# Generate 5 sample reviews\n",
        "for _ in range(5):\n",
        "    print(generate_text(ngram_model, \"My favorite movie\", num_words=20, n=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7omgFSEjFVWK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data_iter, vocab, tokenizer):\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        for label, text in data_iter:\n",
        "            # Ensure to handle unknown tokens, assuming vocab returns a special index for unknown tokens\n",
        "            numericalized_text = [self.vocab.get('<start>', self.vocab.get('<unk>'))] + \\\n",
        "                                 [self.vocab.get(token, self.vocab.get('<unk>')) for token in self.tokenizer(text)] + \\\n",
        "                                 [self.vocab.get('<end>', self.vocab.get('<unk>'))]\n",
        "            self.data.append((numericalized_text, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        numericalized_text, label = self.data[idx]\n",
        "        input_sequence = torch.tensor(numericalized_text[:-1], dtype=torch.long)\n",
        "        target_sequence = torch.tensor(numericalized_text[1:], dtype=torch.long)\n",
        "        return input_sequence, target_sequence, label  # Including label for supervised training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AH_389fOFVWL"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "vocab_size = len(vocab)  # Assuming vocab is already built as shown above\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v0JZd8RuFVWL"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Function to yield tokens from the IMDB dataset\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Load the dataset iterator\n",
        "train_iter = IMDB(split='train')\n",
        "\n",
        "# Build the vocabulary from the iterator\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>', '<pad>', '<start>', '<end>'])\n",
        "\n",
        "# Set special tokens and their indexes\n",
        "vocab.set_default_index(vocab['<unk>'])  # Set default index for unknown tokens\n",
        "\n",
        "# Assuming you now have a 'vocab' object properly set up, you can proceed with using it in your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KMVGJw5dFVWL"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmZo6A8bFVWL",
        "outputId": "b2e4c754-c074-47e3-ff4a-20d9c0d0322b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-bdf70b4b145c>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_sequences_padded = pad_sequence([torch.tensor(seq) for seq in input_sequences], batch_first=True, padding_value=0)\n",
            "<ipython-input-14-bdf70b4b145c>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  targets_padded = pad_sequence([torch.tensor(tgt) for tgt in targets], batch_first=True, padding_value=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.998318374156952\n",
            "Epoch 2, Loss: 2.962448127567768\n",
            "Epoch 3, Loss: 2.9193638637661934\n",
            "Epoch 4, Loss: 2.8279527500271797\n",
            "Epoch 5, Loss: 2.69191175699234\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# LSTMModel definition\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)  # Output layer maps to num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        output = self.fc(output)  # No need to select the last timestep unless it's sequence classification\n",
        "        return output\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, input_sequences, targets):\n",
        "        self.input_sequences = input_sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_sequences[idx], self.targets[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_sequences, targets = zip(*batch)\n",
        "    input_sequences_padded = pad_sequence([torch.tensor(seq) for seq in input_sequences], batch_first=True, padding_value=0)\n",
        "    targets_padded = pad_sequence([torch.tensor(tgt) for tgt in targets], batch_first=True, padding_value=0)\n",
        "    return input_sequences_padded, targets_padded\n",
        "\n",
        "vocab_size = 10000  # Example vocab size\n",
        "num_classes = 20  # Example number of classes\n",
        "\n",
        "input_sequences = torch.randint(0, vocab_size, (1000, 10))  # Adjust as necessary\n",
        "targets = torch.randint(0, num_classes, (1000, 10))  # Adjust as necessary\n",
        "\n",
        "dataset = TextDataset(input_sequences, targets)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim=100, hidden_dim=256, num_classes=num_classes)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Assuming you have a list called 'loss_values' that stores the average loss for each epoch\n",
        "loss_values = []\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for input_sequences, targets in train_loader:\n",
        "        input_sequences, targets = input_sequences.long(), targets.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(input_sequences)\n",
        "\n",
        "        loss = criterion(predictions.view(-1, num_classes), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    loss_values.append(average_loss)\n",
        "    print(f'Epoch {epoch+1}, Loss: {average_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Adjusted file path for Google Colab environment\n",
        "file_path = '/content/bul.txt'\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read()\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "else:\n",
        "    print(\"File not found. Please check the file path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py6dYSNXNYKG",
        "outputId": "af8d3c0c-2a73-4d89-df68-6dc3b08ff826"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "cxnSjUPzP3xM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings = {}\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example vocab list - replace with your actual vocab\n",
        "vocab = ['hello', 'world', '<unk>', '<pad>']  # Example vocabulary\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 100  # Dimensionality of GloVe vectors you loaded\n",
        "weights_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Create a weights matrix to initialize the embedding layer\n",
        "for i, word in enumerate(vocab):\n",
        "    try:\n",
        "        weights_matrix[i] = glove_embeddings[word]\n",
        "    except KeyError:\n",
        "        # Initialize with a random vector if the word is not in GloVe\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim, ))\n",
        "\n",
        "# Create an embedding layer and load the GloVe weights\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedding_layer.weight.data.copy_(torch.from_numpy(weights_matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKU0VfK2ib5s",
        "outputId": "6348eaab-3a4f-4a20-ff6a-9c6bc4791e7b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.6688e-01,  3.9632e-01,  6.1690e-01, -7.7451e-01, -1.0390e-01,\n",
              "          2.6697e-01,  2.7880e-01,  3.0992e-01,  5.4685e-03, -8.5256e-02,\n",
              "          7.3602e-01, -9.8432e-02,  5.4790e-01, -3.0305e-02,  3.3479e-01,\n",
              "          1.4094e-01, -7.0003e-03,  3.2569e-01,  2.2902e-01,  4.6557e-01,\n",
              "         -1.9531e-01,  3.7491e-01, -7.1390e-01, -5.1775e-01,  7.7039e-01,\n",
              "          1.0881e+00, -6.6011e-01, -1.6234e-01,  9.1190e-01,  2.1046e-01,\n",
              "          4.7494e-02,  1.0019e+00,  1.1133e+00,  7.0094e-01, -8.6960e-02,\n",
              "          4.7571e-01,  1.6360e-01, -4.4469e-01,  4.4690e-01, -9.3817e-01,\n",
              "          1.3101e-02,  8.5964e-02, -6.7456e-01,  4.9662e-01, -3.7827e-02,\n",
              "         -1.1038e-01, -2.8612e-01,  7.4606e-02, -3.1527e-01, -9.3774e-02,\n",
              "         -5.7069e-01,  6.6865e-01,  4.5307e-01, -3.4154e-01, -7.1660e-01,\n",
              "         -7.5273e-01,  7.5212e-02,  5.7903e-01, -1.1910e-01, -1.1379e-01,\n",
              "         -1.0026e-01,  7.1341e-01, -1.1574e+00, -7.4026e-01,  4.0452e-01,\n",
              "          1.8023e-01,  2.1449e-01,  3.7638e-01,  1.1239e-01, -5.3639e-01,\n",
              "         -2.5092e-02,  3.1886e-01, -2.5013e-01, -6.3283e-01, -1.1843e-02,\n",
              "          1.3770e+00,  8.6013e-01,  2.0476e-01, -3.6815e-01, -6.8874e-01,\n",
              "          5.3512e-01, -4.6556e-01,  2.7389e-01,  4.1180e-01, -8.5400e-01,\n",
              "         -4.6288e-02,  1.1304e-01, -2.7326e-01,  1.5636e-01, -2.0334e-01,\n",
              "          5.3586e-01,  5.9784e-01,  6.0469e-01,  1.3735e-01,  4.2232e-01,\n",
              "         -6.1279e-01, -3.8486e-01,  3.5842e-01, -4.8464e-01,  3.0728e-01],\n",
              "        [ 4.9177e-01,  1.1164e+00,  1.1424e+00,  1.4381e-01, -1.0696e-01,\n",
              "         -4.6727e-01, -4.4374e-01, -8.8024e-03, -5.0406e-01, -2.0549e-01,\n",
              "          5.0910e-01, -6.0904e-01,  2.0980e-01, -4.4836e-01, -7.0383e-01,\n",
              "          2.1516e-01,  6.6189e-01,  3.4620e-01, -8.9294e-01, -4.8032e-01,\n",
              "          4.3069e-01,  3.5697e-01,  8.4277e-01,  5.2344e-01,  8.2065e-01,\n",
              "          5.3183e-04,  2.4835e-01, -2.0887e-01,  8.1657e-01,  2.5048e-01,\n",
              "         -7.4761e-01, -1.1309e-02, -4.7481e-01,  6.4520e-02,  5.4517e-01,\n",
              "          2.0714e-01, -4.6237e-01,  1.0724e+00, -1.0526e+00, -1.5567e-01,\n",
              "         -7.9339e-01, -2.8366e-02,  1.0138e-01, -2.0909e-01,  4.5513e-01,\n",
              "          4.7330e-01,  6.8859e-01, -2.3840e-01, -5.5178e-02, -8.3022e-01,\n",
              "         -4.7127e-01,  2.2713e-01,  4.2651e-02,  1.1273e+00, -8.4776e-02,\n",
              "         -3.0378e+00, -1.8389e-01,  7.8244e-01,  1.6395e+00,  7.6146e-01,\n",
              "         -1.4258e-01,  6.5115e-01, -1.3549e-02, -5.1465e-01,  6.6951e-01,\n",
              "         -3.4464e-01, -1.4525e-01,  4.9258e-01,  8.0085e-01, -5.4971e-01,\n",
              "          3.9657e-01, -4.8571e-01, -4.3846e-01,  3.3180e-01,  1.0356e-01,\n",
              "         -2.8987e-02,  1.0896e-01, -4.5671e-01, -1.1150e+00, -8.2366e-02,\n",
              "          1.0186e+00,  3.0639e-02, -3.7162e-01,  1.0742e+00, -1.0642e+00,\n",
              "         -2.0298e-01, -9.8434e-01, -3.2040e-01,  1.5969e-01, -1.7910e-01,\n",
              "          2.1325e-01,  4.7155e-01,  6.8247e-01,  1.3784e-01, -1.0704e-01,\n",
              "         -1.8294e-01, -4.0082e-01, -5.0885e-01,  6.2556e-01,  4.3917e-01],\n",
              "        [-7.1802e-01, -2.0196e+00,  2.1978e-01,  2.2690e-01, -6.4724e-01,\n",
              "         -1.6704e-01,  8.0309e-01, -7.6320e-01, -3.0836e-01,  6.6806e-01,\n",
              "         -6.1151e-01,  5.1984e-01,  1.0513e+00,  4.0622e-01, -7.5581e-01,\n",
              "         -6.6434e-01, -5.3676e-01, -3.8725e-01, -6.2848e-01,  4.7783e-01,\n",
              "         -9.2717e-02, -3.3184e-02, -5.2810e-01, -1.4919e-01,  7.1075e-01,\n",
              "          2.4626e-01, -9.0577e-02, -7.1781e-01, -6.9672e-01,  3.1957e-01,\n",
              "          6.6776e-02,  3.1894e-01, -1.9118e-01, -5.8624e-01, -4.5729e-01,\n",
              "         -7.0826e-02,  9.2012e-01,  8.5028e-02,  9.9592e-02, -6.2395e-01,\n",
              "         -2.0786e-01, -6.9034e-01,  4.6501e-02, -4.8834e-01, -5.5063e-01,\n",
              "         -1.9083e-01, -2.3220e-01, -7.8525e-01,  1.1722e-01, -4.2269e-01,\n",
              "         -1.8003e-01, -2.1459e-01,  3.7731e-01, -1.9016e-01,  6.7387e-01,\n",
              "          1.0935e-01, -2.6209e-01, -4.6596e-01,  3.4190e-01,  5.1673e-01,\n",
              "         -7.7112e-01,  1.3310e-01,  2.9053e-01,  5.0209e-01,  4.6153e-01,\n",
              "          6.2864e-02, -3.3985e-01, -1.4472e+00,  2.3840e-01, -5.4445e-01,\n",
              "          1.0897e+00, -2.9509e-01, -1.0302e+00, -3.2784e-02, -2.6178e-01,\n",
              "         -5.9035e-01, -1.0420e-01,  1.0494e+00,  6.8488e-01, -2.6955e-01,\n",
              "         -9.2905e-01,  1.4638e-01, -1.4110e-01,  1.3211e+00, -5.5699e-01,\n",
              "          8.3480e-01,  1.4090e+00, -2.1395e-01, -5.0718e-01,  7.9747e-01,\n",
              "          9.9888e-01, -2.1994e-01, -5.6241e-01,  4.7768e-01, -8.1518e-02,\n",
              "         -5.0171e-02, -5.9798e-02, -3.2023e-02,  5.2360e-01,  9.0690e-01],\n",
              "        [ 1.5005e+00,  1.9663e-01, -4.6331e-01, -4.8460e-02,  1.2671e-01,\n",
              "          3.3706e-01, -2.4203e-01,  2.3327e-01, -8.9843e-01, -1.8655e-01,\n",
              "         -2.0469e-01,  1.0111e+00,  6.8077e-01,  4.7373e-02, -4.3833e-01,\n",
              "         -5.2894e-01,  6.1737e-01,  2.7591e-02,  6.6789e-01, -3.5140e-01,\n",
              "          6.8201e-01, -2.1492e-02,  6.3942e-01, -1.4255e-01, -2.8334e-01,\n",
              "          4.0237e-02,  6.9173e-01, -7.4331e-01,  4.1690e-01,  6.6979e-01,\n",
              "          1.0471e+00,  4.6702e-01, -9.0984e-01,  7.2974e-01,  1.0261e+00,\n",
              "          2.0245e-02, -5.0070e-01,  4.2310e-01, -9.5232e-01,  4.1447e-01,\n",
              "          6.4917e-01, -5.1690e-01, -2.4523e-01,  4.1184e-01, -8.2112e-02,\n",
              "         -2.9253e-01,  9.4388e-03,  8.6751e-01,  2.8866e-01, -5.2198e-01,\n",
              "         -1.5381e-01,  2.0258e-01, -3.6887e-01, -2.5974e-01,  1.1471e+00,\n",
              "          4.9587e-01,  7.6849e-01, -7.3767e-01,  1.0526e+00, -5.1908e-01,\n",
              "          3.2017e-01,  8.4413e-01,  6.1128e-01, -3.6871e-01, -1.9650e-01,\n",
              "         -8.1144e-01,  4.0752e-01, -1.4042e+00,  4.6195e-01,  2.4369e-01,\n",
              "          6.8117e-01, -5.2560e-02, -1.9257e-01, -6.4858e-01,  6.9823e-01,\n",
              "          3.7289e-01,  4.2637e-01,  3.9991e-01,  8.6421e-03, -3.4601e-01,\n",
              "          2.5685e-01,  1.1989e-01,  7.8753e-01, -1.4221e+00, -5.9027e-01,\n",
              "         -1.4649e-01,  5.6864e-01, -2.3259e-01, -7.1906e-01,  5.4820e-01,\n",
              "          8.7893e-02,  3.5851e-02, -5.3065e-01,  9.5521e-01, -3.1593e-01,\n",
              "          1.4227e+00, -3.3876e-01, -6.4446e-02,  3.1717e-01, -1.3904e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mypytorchenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
